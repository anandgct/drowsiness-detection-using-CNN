{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f285f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "####importing the neccesary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ae79a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.listdir(\"H:/UK/Ann/train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34566af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 65,  60,  54],\n",
       "        [ 65,  60,  54],\n",
       "        [ 65,  60,  54],\n",
       "        ...,\n",
       "        [254, 254, 254],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[ 65,  60,  54],\n",
       "        [ 65,  60,  54],\n",
       "        [ 65,  60,  54],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[ 65,  60,  54],\n",
       "        [ 65,  60,  54],\n",
       "        [ 65,  60,  54],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 22,  25,  34],\n",
       "        [ 22,  25,  34],\n",
       "        [ 23,  26,  35],\n",
       "        ...,\n",
       "        [157, 165, 178],\n",
       "        [156, 164, 177],\n",
       "        [156, 164, 177]],\n",
       "\n",
       "       [[ 22,  25,  34],\n",
       "        [ 22,  25,  34],\n",
       "        [ 23,  26,  35],\n",
       "        ...,\n",
       "        [155, 163, 176],\n",
       "        [155, 163, 176],\n",
       "        [155, 163, 176]],\n",
       "\n",
       "       [[ 22,  25,  34],\n",
       "        [ 22,  25,  34],\n",
       "        [ 23,  26,  35],\n",
       "        ...,\n",
       "        [154, 162, 175],\n",
       "        [154, 162, 175],\n",
       "        [155, 163, 176]]], dtype=uint8)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_img = plt.imread(\"H:/UK/Ann/train/yawn/10.jpg\")\n",
    "sample_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3ff0da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def face_yawn(direc=\"H:/UK/Ann/train\", fac_path=\"H:/UK/Ann/haarcascade_frontalface_default.xml\"):\n",
    "    yaw_no = []\n",
    "    IMG_SIZE = 145\n",
    "    categories = [\"yawn\", \"no_yawn\"]\n",
    "    for category in categories:\n",
    "        link_path = os.path.join(direc, category)\n",
    "        class_num1 = categories.index(category)\n",
    "        print(class_num1)\n",
    "        for image in os.listdir(link_path):\n",
    "            image_array = cv2.imread(os.path.join(link_path, image), cv2.IMREAD_COLOR)\n",
    "            face_cascade = cv2.CascadeClassifier(fac_path)\n",
    "            faces = face_cascade.detectMultiScale(image_array, 1.3, 5)\n",
    "            for (x, y, w, h) in faces:\n",
    "                img = cv2.rectangle(image_array, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                roi_color = img[y:y+h, x:x+w]\n",
    "                resized_array = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))\n",
    "                yaw_no.append([resized_array, class_num1])\n",
    "    return yaw_no\n",
    "\n",
    "\n",
    "yawn_no_yawn = face_yawn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bee88506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dir_path=\"H:/UK/Ann/train\", face_cas=\"H:/UK/Ann/haarcascade_frontalface_default.xml\", eye_cas=\"H:/UK/Ann/haarcascade.xml\"):\n",
    "    data_path = ['Closed', 'Open']\n",
    "    IMG_SIZE = 145\n",
    "    data = []\n",
    "    for label in data_path:\n",
    "        path = os.path.join(dir_path, label)\n",
    "        class_num = data_path.index(label)\n",
    "        class_num +=2\n",
    "        print(class_num)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "                resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                data.append([resized_array, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0da1827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "data_train = get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7d4c79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data():\n",
    "    yaw_no = face_yawn()\n",
    "    data = get_data()\n",
    "    yaw_no.extend(data)\n",
    "    return np.array(yaw_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e71fba2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91915\\AppData\\Local\\Temp\\ipykernel_23300\\4262209164.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(yaw_no)\n"
     ]
    }
   ],
   "source": [
    "new_data = append_data()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6ac7ad2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "810dd3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for feature, label in new_data:\n",
    "    X.append(feature)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ed1e11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X.reshape(-1, 145, 145, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ffddc0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling = LabelBinarizer()\n",
    "y = labeling.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "282c658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca7989b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "65d83289",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "test_size = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f36e492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1/255, zoom_range=0.2, horizontal_flip=True, rotation_range=30)\n",
    "test_gen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_gen = train_gen.flow(np.array(X_train), y_train, shuffle=False)\n",
    "test_gen = test_gen.flow(np.array(X_test), y_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9880375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 143, 143, 256)     7168      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 71, 71, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 69, 69, 128)       295040    \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 34, 34, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 32, 32, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 14, 14, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 7, 7, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1568)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1568)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                100416    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 495,140\n",
      "Trainable params: 495,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_def = Sequential()\n",
    "\n",
    "model_def.add(Conv2D(256, (3, 3), activation=\"relu\", input_shape=X_train.shape[1:]))\n",
    "model_def.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model_def.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "model_def.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model_def.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model_def.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model_def.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model_def.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model_def.add(Flatten())\n",
    "model_def.add(Dropout(0.5))\n",
    "\n",
    "model_def.add(Dense(64, activation=\"relu\"))\n",
    "model_def.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "model_def.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "\n",
    "model_def.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "51449211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 173s 4s/step - loss: 0.9721 - accuracy: 0.5861 - val_loss: 0.7642 - val_accuracy: 0.7539\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 172s 4s/step - loss: 0.4348 - accuracy: 0.8181 - val_loss: 0.4577 - val_accuracy: 0.7923\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 184s 4s/step - loss: 0.3382 - accuracy: 0.8510 - val_loss: 0.2784 - val_accuracy: 0.8831\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 180s 4s/step - loss: 0.3099 - accuracy: 0.8750 - val_loss: 0.2729 - val_accuracy: 0.8988\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 171s 4s/step - loss: 0.2655 - accuracy: 0.8975 - val_loss: 0.2861 - val_accuracy: 0.9005\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 161s 4s/step - loss: 0.2470 - accuracy: 0.8997 - val_loss: 0.2763 - val_accuracy: 0.8935\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 171s 4s/step - loss: 0.2145 - accuracy: 0.9154 - val_loss: 0.2460 - val_accuracy: 0.9127\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 175s 4s/step - loss: 0.2133 - accuracy: 0.9154 - val_loss: 0.2157 - val_accuracy: 0.9232\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 168s 4s/step - loss: 0.2073 - accuracy: 0.9192 - val_loss: 0.2479 - val_accuracy: 0.9180\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 170s 4s/step - loss: 0.2067 - accuracy: 0.9207 - val_loss: 0.2300 - val_accuracy: 0.9337\n"
     ]
    }
   ],
   "source": [
    "History = model_def.fit(train_gen, epochs=25, validation_data=test_gen, shuffle=True, validation_steps=len(test_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b39ba068",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'final'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mfinal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m final\u001b[38;5;241m.\u001b[39mfinal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m loss \u001b[38;5;241m=\u001b[39m final\u001b[38;5;241m.\u001b[39mfinal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'History' object has no attribute 'final'"
     ]
    }
   ],
   "source": [
    "accuracy = History.History ['accuracy']\n",
    "val_accuracy = History.History ['val_accuracy']\n",
    "loss = History.History['loss']\n",
    "val_loss = History.History['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, \"g\", label=\"trainning accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"r\", label=\"validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, \"g\", label=\"trainning loss\")\n",
    "plt.plot(epochs, val_loss, \"r\", label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "443c9d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_def.save(\"dorwsii.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aad4b5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 10s 581ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction=np.argmax(model_def.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c57bb40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]\n",
    "IMG_SIZE = 145\n",
    "def predict(filepath, face_cas=\"H:/UK/Ann/haarcascade_frontalface_default.xml\"):\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
    "    img_array = img_array / 255\n",
    "    resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return resized_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "model_pre = tf.keras.models.load_model(\"C:/Users/91915/dorwsii.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "02edfd4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels_new\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\13004598\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2310\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[0;32m   2196\u001b[0m     y_true,\n\u001b[0;32m   2197\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2205\u001b[0m ):\n\u001b[0;32m   2206\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m \n\u001b[0;32m   2208\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2307\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2310\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2313\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32m~\\.conda\\envs\\13004598\\lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.argmax(y_test, axis=1), prediction, target_names=labels_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "406eb2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 204ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model_pre.predict([predict(\"H:/UK/Ann/testing/test5cl.jpg\")])\n",
    "np.argmax(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
