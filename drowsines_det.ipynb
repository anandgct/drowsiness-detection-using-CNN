{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the neccesary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3348729",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.listdir(\"H:/UK/Ann/train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fdc412",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = plt.imread(\"H:/UK/Ann/train/yawn/10.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d679475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_yawn(direc=\"H:/UK/Ann/train\", fac_path=\"H:/UK/Ann/haarcascade_frontalface_default.xml\"):\n",
    "    yaw_no = []\n",
    "    IMG_SIZE = 145\n",
    "    categories = [\"yawn\", \"no_yawn\"]\n",
    "    for category in categories:\n",
    "        link_path = os.path.join(direc, category)\n",
    "        class_num1 = categories.index(category)\n",
    "        print(class_num1)\n",
    "        for image in os.listdir(link_path):\n",
    "            image_array = cv2.imread(os.path.join(link_path, image), cv2.IMREAD_COLOR)\n",
    "            face_cascade = cv2.CascadeClassifier(fac_path)\n",
    "            faces = face_cascade.detectMultiScale(image_array, 1.3, 5)\n",
    "            for (x, y, w, h) in faces:\n",
    "                img = cv2.rectangle(image_array, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                roi_color = img[y:y+h, x:x+w]\n",
    "                resized_array = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))\n",
    "                yaw_no.append([resized_array, class_num1])\n",
    "    return yaw_no\n",
    "\n",
    "\n",
    "yawn_no_yawn = face_yawn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbb87bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dir_path=\"H:/UK/Ann/train\", face_cas=\"H:/UK/Ann/haarcascade_frontalface_default.xml\", eye_cas=\"H:/UK/Ann/haarcascade.xml\"):\n",
    "    data_path = ['Closed', 'Open']\n",
    "    IMG_SIZE = 145\n",
    "    data = []\n",
    "    for label in data_path:\n",
    "        path = os.path.join(dir_path, label)\n",
    "        class_num = data_path.index(label)\n",
    "        class_num +=2\n",
    "        print(class_num)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "                resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                data.append([resized_array, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7896b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data():\n",
    "    yaw_no = face_yawn()\n",
    "    data = get_data()\n",
    "    yaw_no.extend(data)\n",
    "    return np.array(yaw_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = append_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34624d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for feature, label in new_data:\n",
    "    X.append(feature)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee1f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X.reshape(-1, 145, 145, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c4b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling = LabelBinarizer()\n",
    "y = labeling.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "test_size = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66957f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1/255, zoom_range=0.2, horizontal_flip=True, rotation_range=30)\n",
    "test_gen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_gen = train_gen.flow(np.array(X_train), y_train, shuffle=False)\n",
    "test_gen = test_gen.flow(np.array(X_test), y_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d57b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_def = Sequential()\n",
    "\n",
    "model_def.add(Conv2D(256, (3, 3), activation=\"relu\", input_shape=X_train.shape[1:]))\n",
    "model_def.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model_def.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "model_def.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model_def.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model_def.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model_def.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model_def.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model_def.add(Flatten())\n",
    "model_def.add(Dropout(0.5))\n",
    "\n",
    "model_def.add(Dense(64, activation=\"relu\"))\n",
    "model_def.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "model_def.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "\n",
    "model_def.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "History = model_def.fit(train_gen, epochs=25, validation_data=test_gen, shuffle=True, validation_steps=len(test_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18686729",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = History.History ['accuracy']\n",
    "val_accuracy = History.History ['val_accuracy']\n",
    "loss = History.History['loss']\n",
    "val_loss = History.History['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, \"g\", label=\"trainning accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"r\", label=\"validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, \"g\", label=\"trainning loss\")\n",
    "plt.plot(epochs, val_loss, \"r\", label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_def.save(\"dorwsii.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69362f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=np.argmax(model_def.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77f36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]\n",
    "IMG_SIZE = 145\n",
    "def predict(filepath, face_cas=\"H:/UK/Ann/haarcascade_frontalface_default.xml\"):\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
    "    img_array = img_array / 255\n",
    "    resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return resized_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "model_pre = tf.keras.models.load_model(\"C:/Users/91915/dorwsii.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.argmax(y_test, axis=1), prediction, target_names=labels_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c9f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_pre.predict([predict(\"H:/UK/Ann/testing/test5cl.jpg\")])\n",
    "np.argmax(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
